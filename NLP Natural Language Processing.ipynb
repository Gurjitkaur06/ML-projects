{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f69a9a2",
   "metadata": {},
   "source": [
    "## Noise Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd0351de",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'NLP enables computers to understand natural language as humans do. Whether the language is spoken or written, natural language processing uses artificial intelligence to take real-world input, process it, and make sense of it in a way a computer can understand. Just as humans have different sensors -- such as ears to hear and eyes to see -- computers have programs to read and microphones to collect audio. And just as humans have a brain to process that input, computers have a program to process their respective inputs. At some point in processing, the input is converted to code that the computer can understand.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1da7bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NLP enables computers to understand natural language as humans do. Whether the language is spoken or written, natural language processing uses artificial intelligence to take real-world input, process it, and make sense of it in a way a computer can understand. Just as humans have different sensors -- such as ears to hear and eyes to see -- computers have programs to read and microphones to collect audio. And just as humans have a brain to process that input, computers have a program to process their respective inputs. At some point in processing, the input is converted to code that the computer can understand.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52cdbbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will remove the noisy words from the text (Stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "140db5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_list = ['in','as','a','it','the','is','are','to','and','this','that','with','at','have']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c7aedc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(input_text):\n",
    "    words = input_text.lower().split()\n",
    "    noise_free_words = [w for w in words if w not in noisy_list]\n",
    "    noise_free_sent = ' '.join(noise_free_words)\n",
    "    return noise_free_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ae65375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nlp enables computers understand natural language humans do. whether language spoken or written, natural language processing uses artificial intelligence take real-world input, process it, make sense of way computer can understand. just humans different sensors -- such ears hear eyes see -- computers programs read microphones collect audio. just humans brain process input, computers program process their respective inputs. some point processing, input converted code computer can understand.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_noise(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d27de4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e05f59ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLP',\n",
       " 'enables',\n",
       " 'computers',\n",
       " 'to',\n",
       " 'understand',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'as',\n",
       " 'humans',\n",
       " 'do',\n",
       " '.',\n",
       " 'Whether',\n",
       " 'the',\n",
       " 'language',\n",
       " 'is',\n",
       " 'spoken',\n",
       " 'or',\n",
       " 'written',\n",
       " ',',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'uses',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'to',\n",
       " 'take',\n",
       " 'real-world',\n",
       " 'input',\n",
       " ',',\n",
       " 'process',\n",
       " 'it',\n",
       " ',',\n",
       " 'and',\n",
       " 'make',\n",
       " 'sense',\n",
       " 'of',\n",
       " 'it',\n",
       " 'in',\n",
       " 'a',\n",
       " 'way',\n",
       " 'a',\n",
       " 'computer',\n",
       " 'can',\n",
       " 'understand',\n",
       " '.',\n",
       " 'Just',\n",
       " 'as',\n",
       " 'humans',\n",
       " 'have',\n",
       " 'different',\n",
       " 'sensors',\n",
       " '--',\n",
       " 'such',\n",
       " 'as',\n",
       " 'ears',\n",
       " 'to',\n",
       " 'hear',\n",
       " 'and',\n",
       " 'eyes',\n",
       " 'to',\n",
       " 'see',\n",
       " '--',\n",
       " 'computers',\n",
       " 'have',\n",
       " 'programs',\n",
       " 'to',\n",
       " 'read',\n",
       " 'and',\n",
       " 'microphones',\n",
       " 'to',\n",
       " 'collect',\n",
       " 'audio',\n",
       " '.',\n",
       " 'And',\n",
       " 'just',\n",
       " 'as',\n",
       " 'humans',\n",
       " 'have',\n",
       " 'a',\n",
       " 'brain',\n",
       " 'to',\n",
       " 'process',\n",
       " 'that',\n",
       " 'input',\n",
       " ',',\n",
       " 'computers',\n",
       " 'have',\n",
       " 'a',\n",
       " 'program',\n",
       " 'to',\n",
       " 'process',\n",
       " 'their',\n",
       " 'respective',\n",
       " 'inputs',\n",
       " '.',\n",
       " 'At',\n",
       " 'some',\n",
       " 'point',\n",
       " 'in',\n",
       " 'processing',\n",
       " ',',\n",
       " 'the',\n",
       " 'input',\n",
       " 'is',\n",
       " 'converted',\n",
       " 'to',\n",
       " 'code',\n",
       " 'that',\n",
       " 'the',\n",
       " 'computer',\n",
       " 'can',\n",
       " 'understand',\n",
       " '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b43b6551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(input_text):\n",
    "    words = word_tokenize(input_text.lower())\n",
    "    noise_free_words = [w for w in words if w not in noisy_list]\n",
    "    noise_free_sent = ' '.join(noise_free_words)\n",
    "    return noise_free_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df65695f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nlp enables computers understand natural language humans do . whether language spoken or written , natural language processing uses artificial intelligence take real-world input , process , make sense of way computer can understand . just humans different sensors -- such ears hear eyes see -- computers programs read microphones collect audio . just humans brain process input , computers program process their respective inputs . some point processing , input converted code computer can understand .'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_noise(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1366c29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing regex pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd6ac484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fda79f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match\n"
     ]
    }
   ],
   "source": [
    "pattern = '^a...s$'\n",
    "test_string = 'abyss'\n",
    "match = re.match(pattern, test_string)\n",
    "\n",
    "\n",
    "if match:\n",
    "    print('Match')\n",
    "else:\n",
    "    print('Not Match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19b49923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'e', 'o', 'a', 'e']\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "pattern = '[aeiou]'\n",
    "test_string = 'aeroplane'\n",
    "match = re.findall(pattern, test_string)\n",
    "print(match)\n",
    "print(len(match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "052de012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 1), match='a'>\n",
      "<re.Match object; span=(1, 2), match='e'>\n",
      "<re.Match object; span=(3, 4), match='o'>\n",
      "<re.Match object; span=(6, 7), match='a'>\n",
      "<re.Match object; span=(8, 9), match='e'>\n"
     ]
    }
   ],
   "source": [
    "pattern = '[aeiou]'\n",
    "test_string = 'aeroplane'\n",
    "match = re.finditer(pattern, test_string)\n",
    "\n",
    "for i in match:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "397c918d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gurjeetkaurgmailcom"
     ]
    }
   ],
   "source": [
    "pattern = '[a-z]'\n",
    "test_string = 'gurjeetkaur.5674@gmail.com'\n",
    "match = re.findall(pattern, test_string)\n",
    "\n",
    "for i in match:\n",
    "    print(i, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27fc1e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".5674@."
     ]
    }
   ],
   "source": [
    "pattern = '[^a-z]'\n",
    "test_string = 'gurjeetkaur.5674@gmail.com'\n",
    "match = re.findall(pattern, test_string)\n",
    "\n",
    "for i in match:\n",
    "    print(i, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c32f034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gur jee tka ur. 567 4@g mai l.c "
     ]
    }
   ],
   "source": [
    "pattern = '...'\n",
    "test_string = 'gurjeetkaur.5674@gmail.com'\n",
    "match = re.findall(pattern, test_string)\n",
    "\n",
    "for i in match:\n",
    "    print(i, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ec40470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 1), match='g'>\n"
     ]
    }
   ],
   "source": [
    "pattern = '^g'\n",
    "test_string = 'gurjeetkaur.5674@gmail.com'\n",
    "match = re.match(pattern, test_string)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aaff1539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['m', 'm']\n"
     ]
    }
   ],
   "source": [
    "pattern = '[m$]'\n",
    "test_string = 'gurjeetkaur.5674@gmail.com'\n",
    "match = re.findall(pattern, test_string)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9af627ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vn']\n"
     ]
    }
   ],
   "source": [
    "pattern = 'vi*n'\n",
    "test_string = 'givng'\n",
    "match = re.findall(pattern, test_string)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce600c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vin']\n"
     ]
    }
   ],
   "source": [
    "pattern = 'vi+n'\n",
    "test_string = 'giving'\n",
    "match = re.findall(pattern, test_string)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7466403f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "pattern = 'vi?n'\n",
    "test_string = 'giviing'\n",
    "match = re.findall(pattern, test_string)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9d538d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ss']\n"
     ]
    }
   ],
   "source": [
    "pattern = 's{2}'\n",
    "test_string = 'missing'\n",
    "match = re.findall(pattern, test_string)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6faeda6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Hastags from twitter feeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ab10a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'ewww that looks gross. #showyourstripes  #loveyourself  #nation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92b40b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_hash(input_text):\n",
    "    pattern = '#[\\w]*'\n",
    "    hastags = re.findall(pattern, input_text)\n",
    "    for i in hastags:\n",
    "        input_text = re.sub(i, '', input_text)\n",
    "    return input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3371665b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ewww that looks gross.     '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_hash(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04a269f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'hey #fellas lovlies, have a og day #standupforyourself'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "158cf285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hey  lovlies, have a og day '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_hash(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b4a6649",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'i visited the website https://twitter.com/comment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab9bfdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_links(input_text):\n",
    "    pattern = 'http[\\w\\S]*'\n",
    "    input_text = re.sub(pattern, '', input_text)\n",
    "    return input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a513dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i visited the website '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_links(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e838c5c",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64907030",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'NLP enables computers to understand natural language as humans do. Whether the language is spoken or written, natural language processing uses artificial intelligence to take real-world input, process it, and make sense of it in a way a computer can understand. Just as humans have different sensors -- such as ears to hear and eyes to see -- computers have programs to read and microphones to collect audio. And just as humans have a brain to process that input, computers have a program to process their respective inputs. At some point in processing, the input is converted to code that the computer can understand.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c617f62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLP',\n",
       " 'enables',\n",
       " 'computers',\n",
       " 'to',\n",
       " 'understand',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'as',\n",
       " 'humans',\n",
       " 'do.',\n",
       " 'Whether',\n",
       " 'the',\n",
       " 'language',\n",
       " 'is',\n",
       " 'spoken',\n",
       " 'or',\n",
       " 'written,',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'uses',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'to',\n",
       " 'take',\n",
       " 'real-world',\n",
       " 'input,',\n",
       " 'process',\n",
       " 'it,',\n",
       " 'and',\n",
       " 'make',\n",
       " 'sense',\n",
       " 'of',\n",
       " 'it',\n",
       " 'in',\n",
       " 'a',\n",
       " 'way',\n",
       " 'a',\n",
       " 'computer',\n",
       " 'can',\n",
       " 'understand.',\n",
       " 'Just',\n",
       " 'as',\n",
       " 'humans',\n",
       " 'have',\n",
       " 'different',\n",
       " 'sensors',\n",
       " '--',\n",
       " 'such',\n",
       " 'as',\n",
       " 'ears',\n",
       " 'to',\n",
       " 'hear',\n",
       " 'and',\n",
       " 'eyes',\n",
       " 'to',\n",
       " 'see',\n",
       " '--',\n",
       " 'computers',\n",
       " 'have',\n",
       " 'programs',\n",
       " 'to',\n",
       " 'read',\n",
       " 'and',\n",
       " 'microphones',\n",
       " 'to',\n",
       " 'collect',\n",
       " 'audio.',\n",
       " 'And',\n",
       " 'just',\n",
       " 'as',\n",
       " 'humans',\n",
       " 'have',\n",
       " 'a',\n",
       " 'brain',\n",
       " 'to',\n",
       " 'process',\n",
       " 'that',\n",
       " 'input,',\n",
       " 'computers',\n",
       " 'have',\n",
       " 'a',\n",
       " 'program',\n",
       " 'to',\n",
       " 'process',\n",
       " 'their',\n",
       " 'respective',\n",
       " 'inputs.',\n",
       " 'At',\n",
       " 'some',\n",
       " 'point',\n",
       " 'in',\n",
       " 'processing,',\n",
       " 'the',\n",
       " 'input',\n",
       " 'is',\n",
       " 'converted',\n",
       " 'to',\n",
       " 'code',\n",
       " 'that',\n",
       " 'the',\n",
       " 'computer',\n",
       " 'can',\n",
       " 'understand.']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb20c246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "81434d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLP',\n",
       " 'enables',\n",
       " 'computers',\n",
       " 'to',\n",
       " 'understand',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'as',\n",
       " 'humans',\n",
       " 'do',\n",
       " '.',\n",
       " 'Whether',\n",
       " 'the',\n",
       " 'language',\n",
       " 'is',\n",
       " 'spoken',\n",
       " 'or',\n",
       " 'written',\n",
       " ',',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'uses',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'to',\n",
       " 'take',\n",
       " 'real-world',\n",
       " 'input',\n",
       " ',',\n",
       " 'process',\n",
       " 'it',\n",
       " ',',\n",
       " 'and',\n",
       " 'make',\n",
       " 'sense',\n",
       " 'of',\n",
       " 'it',\n",
       " 'in',\n",
       " 'a',\n",
       " 'way',\n",
       " 'a',\n",
       " 'computer',\n",
       " 'can',\n",
       " 'understand',\n",
       " '.',\n",
       " 'Just',\n",
       " 'as',\n",
       " 'humans',\n",
       " 'have',\n",
       " 'different',\n",
       " 'sensors',\n",
       " '--',\n",
       " 'such',\n",
       " 'as',\n",
       " 'ears',\n",
       " 'to',\n",
       " 'hear',\n",
       " 'and',\n",
       " 'eyes',\n",
       " 'to',\n",
       " 'see',\n",
       " '--',\n",
       " 'computers',\n",
       " 'have',\n",
       " 'programs',\n",
       " 'to',\n",
       " 'read',\n",
       " 'and',\n",
       " 'microphones',\n",
       " 'to',\n",
       " 'collect',\n",
       " 'audio',\n",
       " '.',\n",
       " 'And',\n",
       " 'just',\n",
       " 'as',\n",
       " 'humans',\n",
       " 'have',\n",
       " 'a',\n",
       " 'brain',\n",
       " 'to',\n",
       " 'process',\n",
       " 'that',\n",
       " 'input',\n",
       " ',',\n",
       " 'computers',\n",
       " 'have',\n",
       " 'a',\n",
       " 'program',\n",
       " 'to',\n",
       " 'process',\n",
       " 'their',\n",
       " 'respective',\n",
       " 'inputs',\n",
       " '.',\n",
       " 'At',\n",
       " 'some',\n",
       " 'point',\n",
       " 'in',\n",
       " 'processing',\n",
       " ',',\n",
       " 'the',\n",
       " 'input',\n",
       " 'is',\n",
       " 'converted',\n",
       " 'to',\n",
       " 'code',\n",
       " 'that',\n",
       " 'the',\n",
       " 'computer',\n",
       " 'can',\n",
       " 'understand',\n",
       " '.']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "70499c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLP enables computers to understand natural language as humans do.',\n",
       " 'Whether the language is spoken or written, natural language processing uses artificial intelligence to take real-world input, process it, and make sense of it in a way a computer can understand.',\n",
       " 'Just as humans have different sensors -- such as ears to hear and eyes to see -- computers have programs to read and microphones to collect audio.',\n",
       " 'And just as humans have a brain to process that input, computers have a program to process their respective inputs.',\n",
       " 'At some point in processing, the input is converted to code that the computer can understand.']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fb03f2",
   "metadata": {},
   "source": [
    "## Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dcb43216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# playing, plays, played, player, play --> play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "820c85a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d81c9ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1b1068a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a0e9e502",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['Play','Playing','Played','Playable','Happened','Happening','Lovingly','Sportingly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f32251db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Play --> play\n",
      "Playing --> play\n",
      "Played --> play\n",
      "Playable --> playabl\n",
      "Happened --> happen\n",
      "Happening --> happen\n",
      "Lovingly --> lovingli\n",
      "Sportingly --> sportingli\n"
     ]
    }
   ],
   "source": [
    "for w in words:\n",
    "    print(w, '-->', ps.stem(w.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c1d1ff3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb = SnowballStemmer('english',ignore_stopwords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d540967b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Play --> play\n",
      "Playing --> play\n",
      "Played --> play\n",
      "Playable --> playabl\n",
      "Happened --> happen\n",
      "Happening --> happen\n",
      "Lovingly --> love\n",
      "Sportingly --> sport\n"
     ]
    }
   ],
   "source": [
    "for w in words:\n",
    "    print(w, '-->', sb.stem(w.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dea51e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'he played a very smart and claculated game using all his skills very skillfully defeating his opponents'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "058fad4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " he play a very smart and clacul game use all his skill very skill defeat his oppon\n"
     ]
    }
   ],
   "source": [
    "new_w=''\n",
    "for w in text.split():\n",
    "    new_w = new_w+' '+sb.stem(w.lower())\n",
    "print(new_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "93515303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "923da85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "05dbe72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e8f393a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "37eccfb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Play --> play\n",
      "Playing --> playing\n",
      "Played --> played\n",
      "Playable --> playable\n",
      "Happened --> happened\n",
      "Happening --> happening\n",
      "Lovingly --> lovingly\n",
      "Sportingly --> sportingly\n",
      "biggest --> big\n",
      "worse --> bad\n",
      "always --> always\n",
      "beautifully --> beautifully\n"
     ]
    }
   ],
   "source": [
    "words = ['Play','Playing','Played','Playable','Happened','Happening','Lovingly','Sportingly','biggest','worse','always','beautifully']\n",
    "for w in words:\n",
    "    print(w, '-->', lm.lemmatize(w.lower(),pos='a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a78f208d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dac6f85",
   "metadata": {},
   "source": [
    "## Object Standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2bd8811d",
   "metadata": {},
   "outputs": [],
   "source": [
    "abbrev = {'ty':'thank you',\n",
    "         'idk':'I dont know',\n",
    "         'ttyl':'talk to you later',\n",
    "         'tbh':'to be honest',\n",
    "         'lol':'laugh out loud'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a142db64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abb_words(text):\n",
    "    words = word_tokenize(text)\n",
    "    new_word = []\n",
    "    for w in words:\n",
    "        if w in abbrev:\n",
    "            w = abbrev[w]\n",
    "        new_word.append(w)\n",
    "    new_sent = ' '.join(new_word)\n",
    "    return new_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3269d1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thank you so much I dont know how i will repay you for everything , to be honest you are great , talk to you later'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abb_words('ty so much idk how i will repay you for everything, tbh you are great, ttyl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c80272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
